name: Run Eval Suite

on:
  workflow_dispatch:
    inputs:
      branch:
        description: 'Branch of pgai to use'
        required: true
        type: string
        default: 'jgpruitt/semantic-catalog'
      task:
        description: What task to evaluate
        required: true
        type: choice
        default: 'text_to_sql'
        options:
          - get_tables
          - text_to_sql
      agent:
        description: What agent to use
        required: true
        type: choice
        default: 'pgai'
        options:
          - baseline
          - pgai
          - vanna
      load_provider:
        description: What provider to use for loading data
        required: true
        type: choice
        default: 'openai'
        options:
          - ollama
          - openai
          - sentence_transformers
      load_model:
        description: What model to use for loading data
        required: false
        type: string
        default: ''
      load_dimensions:
        description: Number of dimensions to use for loading data
        required: true
        type: number
        default: 576
      eval_provider:
        description: What provider to use for eval
        required: true
        type: choice
        default: 'anthropic'
        options:
          - anthropic
          - ollama
          - openai
      eval_model:
        description: What model to use for eval
        required: false
        type: string
        default: ''
      entire_schema:
        description: Whether to use the entire schema for LLM
        required: true
        type: boolean
        default: false
      gold_tables:
        description: Whether to only use gold tables for LLM
        required: true
        type: boolean
        default: false

jobs:
  generate_matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      load_model: ${{ steps.model.outputs.load_model }}
      eval_model: ${{ steps.model.outputs.eval_model }}
    steps:
      - uses: actions/checkout@v4

      - uses: ./.github/actions/setup-pgai
        with:
          branch: ${{ inputs.branch }}

      - uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          python-version: 3.12
      - run: uv sync
      - name: Setup env vars
        run: |
          echo -e "
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          OLLAMA_HOST=http://localhost:11434
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          POSTGRES_DSN=postgresql://postgres:postgres@localhost:5555
          REPORT_POSTGRES_DSN=${{ secrets.REPORT_POSTGRES_DSN }}
          SOURCE=github-${{ github.actor }}
          " > .env
      - name: Get models
        id: model
        run: |
          echo "load_model=$(uv run python3 -m suite get-model load ${{ inputs.load_provider }} ${{ inputs.load_model }})" >> $GITHUB_OUTPUT
          echo "eval_model=$(uv run python3 -m suite get-model eval ${{ inputs.eval_provider }} ${{ inputs.eval_model }})" >> $GITHUB_OUTPUT

      - name: Generate matrix
        id: set-matrix
        run: echo "matrix=$(uv run python3 -m suite generate-matrix)" >> "$GITHUB_OUTPUT"

      - name: Diagnostic information
        run: |
          echo "load_provider=${{ inputs.load_provider }}"
          echo "load_model=${{ steps.model.outputs.load_model }}"
          echo "load_dimensions=${{ inputs.load_dimensions }}"
          echo "eval_provider=${{ inputs.eval_provider }}"
          echo "eval_model=${{ steps.model.outputs.eval_model }}"
          echo "entire_schema=${{ inputs.entire_schema }}"
          echo "gold_tables=${{ inputs.gold_tables }}"
          echo "matrix="
          echo '${{ steps.set-matrix.outputs.matrix }}' | jq '.'
  run:
    needs: generate_matrix
    runs-on: ubuntu-latest
    strategy:
      # each job will run a different combination of
      # (dataset, database)
      matrix: ${{ fromJson(needs.generate_matrix.outputs.matrix) }}
      fail-fast: false

    steps:
      - name: Run ollama container
        if: ${{ inputs.load_provider == 'ollama' }} || ${{ inputs.eval_provider == 'ollama' }}
        run: docker run -d --network host --name ollama ollama/ollama:0.5.4

      - run: |
          cd /opt
          find . -maxdepth 1 -mindepth 1 '!' -path ./containerd '!' -path ./actionarchivecache '!' -path ./runner '!' -path ./runner-cache -exec rm -rf '{}' ';'

      - uses: actions/checkout@v4

      - uses: ./.github/actions/setup-pgai
        with:
          branch: ${{ inputs.branch }}

      - name: Run timescale container
        run: |
          docker pull timescale/timescaledb-ha:pg17
          docker run -d --name postgres \
            -p 127.0.0.1:5555:5432 \
            -e POSTGRES_HOST_AUTH_METHOD=trust \
            -e POSTGRES_DB=postgres \
            timescale/timescaledb-ha:pg17

      - uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          python-version: 3.12

      - run: uv sync

      - name: Setup env vars
        run: |
          echo -e "
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          OLLAMA_HOST=http://localhost:11434
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          POSTGRES_DSN=postgresql://postgres:postgres@localhost:5555
          REPORT_POSTGRES_DSN=${{ secrets.REPORT_POSTGRES_DSN }}
          SOURCE=github-${{ github.actor }}
          " > .env

      - name: Pull ollama model for loading
        if: ${{ inputs.load_provider == 'ollama' }}
        run: docker exec ollama ollama pull ${{ needs.generate_matrix.outputs.load_model }}

      - name: Pull ollama model for eval
        if: ${{ inputs.eval_provider == 'ollama' }}
        run: docker exec ollama ollama pull ${{ needs.generate_matrix.outputs.eval_model }}

      - name: Load dataset ${{ matrix.dataset }} ${{ matrix.database }}
        run: uv run python3 -m suite load --dataset ${{ matrix.dataset }} --database ${{ matrix.database }}

      - name: Setup dataset ${{ matrix.dataset }} ${{ matrix.database }}
        run: uv run python3 -m suite setup --provider ${{ inputs.load_provider }} --model ${{ needs.generate_matrix.outputs.load_model }} --dimensions ${{ inputs.load_dimensions }} --dataset ${{ matrix.dataset }} --database ${{ matrix.database }} ${{ inputs.agent }}
      - name: Run eval
        run: uv run python3 -m suite eval --dataset ${{ matrix.dataset }} --database ${{ matrix.database }} --provider ${{ inputs.eval_provider }} --model ${{ needs.generate_matrix.outputs.eval_model }} ${{ inputs.entire_schema && '--entire-schema' || '' }} ${{ inputs.gold_tables && '--gold-tables' || '' }} ${{ inputs.agent }} ${{ inputs.task }}

      - run: mv results/results.json results-${{ matrix.dataset }}-${{ matrix.database }}.json

      - name: Upload eval results
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.dataset }}-${{ matrix.database }}.json
          path: results-${{ matrix.dataset }}-${{ matrix.database }}.json

      - name: Clean up
        if: always()
        run: |
          if [ "$(docker ps -aq -f name=postgres)" ]; then
            docker rm -f postgres
          fi

  report_results:
    needs: run
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4

      - uses: ./.github/actions/setup-pgai
        with:
          branch: ${{ inputs.branch }}

      - uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          python-version: 3.12
      - run: uv sync

      - name: Setup env vars
        run: |
          echo -e "
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          OLLAMA_HOST=http://localhost:11434
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          POSTGRES_DSN=postgresql://postgres:postgres@localhost:5555
          REPORT_POSTGRES_DSN=${{ secrets.REPORT_POSTGRES_DSN }}
          SOURCE=github-${{ github.actor }}
          " > .env

      - name: Download eval results
        uses: actions/download-artifact@v4
        with:
          path: results
          merge-multiple: true

      - name: Generate report
        run: uv run python3 -m suite generate-report
